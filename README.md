# motif-generator
Scripts to generate short music functional ear training samples with answers embedded in id3 tag lyrics

## Overview

The Mr. Ear ear training music samples available for download were generated by the Python
scripts in this repos. The scripts depend on the Petrucci melody ngram datasets available
[here](http://www.peachnote.com/datasets.html) from Vladimir Viro.

I began experimenting with these scripts when I realized through much effort at
musical ear training, that the process of developing a good ear for relative pitch in
tonal music was going to take many hours. I had surmised that people who had really
good ears had generally spent many hours playing by ear, ie, learning to hear something
and then play it, initially by trial and error, and eventually with less effort. That
activity is akin to the process of transcribing, which I interpret as meaning to go directly
from sound to symbol (which can either be demonstrated by notating the music or just playing
or singing the music). I tried using ear training software, but my ability was so basic, it
was too boring. I wanted to try something more akin to transcribing. I hypothesized that a large
data set of short mp3 files with music samples that I could put on my mobile phone might
be able to exercise the same brain functions involved in transcribing music.
In order for the music samples to be useful, I knew I needed a way to be able to check my
answers, and I eventually discovered that answers could be put into id3 tags within the mp3
files.

With a trained ear, it is possible to put all the samples into a single playlist and
just by listening, be able to determine the pitch collection and sequence of pitches.
I've worked with various collections of scales and modes, and with added chromatic notes.
To train the ear with these samples, it is probably best to take each collection of samples
on one at a time. Initially, I started with the Diatonic collection (Ionian mode). Since I
couldn't even guesss the answer intially, I would just check the answer and sing along
with solfege syllables. I restrict my solfege to just 12
syllables, do re ra re me mi fa fi so le la te ti,
(phonetically - doe rah ray may mee fah fee sow lay lah tay tee). The answers in the lyrics
use scale degrees, which to me are less confusing than written solfege syllables
(1 ♭2 2 ♭3 3 4 ♯4 5 ♭6 6 ♭7 7). The effort required to get fluent at
translating between the 12 written scale degrees and the 12 spoken solfege syllables was
miniscule compared to the ear training itself.

I found that just listening to samples, trying to come up with the answer before peeking, and
then continuing to sing the sample for a minute or two before moving on has greatly improved my
ear. I liked doing it a lot more than using ear training software, and all I needed was my
phone. Having bootstrapped myself into a better set of ears, I am lately
getting back into ear training software and transcribing.

Each of these samples starts with a tonic cue, which is an arpeggiated major or minor triad. This
provides some context to establish a key. I have experimented with no cue (sticking with a single key)
and 1,5,1 as a cue also. Adding the cue happened after I read Dan Harrison's books, which emphasized
the importance of the dominant pitch for tonal hearing. Using the cue to try and force your ear into
a key allows for hearing chromatic passages as outside notes. My goal has been to recognize all 12
relative pitches.

## Using the Samples

To try out some samples, find the zip file, MrEar.zip, download the zip file, and import the collections in the folders
into a music library or onto a mobile device. Use a music app that can display id3 lyrics embedded in
mp3 files (I have used the built in iPhone music app and MP3+ Player for iPhone). I would be
interested in knowing of others for iPhone. Getting new samples
onto the iPhone using iTunes while experimenting has been a tremendous pain! And one version of IOS dropped
the lyrics display capability altogether (but now back).

I always use random shuffle and repeat 1 song when playing them.

## Generating New Samples

Anyone interested in trying something different could vary the steps outlined below. Maybe try some of the
options. I could say a lot more about things I've tinkered with. Adding the 

The following steps assume a unix environment (I use Cygwin).

### Step 1: Clone this repos or download and explode .zip file

### Step 2: Obtain and reformat the Petrucci datasets (see link above)

Put the imslp-interval-%dgram-20110401.csv files in ../Petrucci, cd into there and run

`../motif-generator/reformatPetrucci.py 1 12`

### Step 3: Generate a midi file of all the samples

Just run:

`genmotifs.py`

Although there are many options, by default, it should generate two files gm.log and gm.mid

### Step 3: Render the gm.mid midi file into a gm.wav audio file

For this step I use Reaper, a Digital Audio Workstation (DAW) application. It would be nice
to automate this step but I liked the sound quality I could get doing it by hand.

### Step 4: Clip the gm.wav file into many short files in subdirectories under gm directory.

Just run:

`clipmotifs.py gm`

This should generate 9 subdirectories with 400-500 .wav samples each. The 9 subdirs contain
melody samples from:
Diatonic (or Ionian), Mixolydian, Aeolian, Dorian, Harmonic Minor, Melodic Minor, Phrygian,
Major Plus 1 Chromatic, and Minor Plus 1 Chromatic.

This step also generates the gm_mp3.sh file for the next step.

### Step 5: Run the gm_mp3.sh to convert the .wav files to .mp3 and to add the lyrics tag

Just run:

`gm_mp3.sh`

This generated script runs `lame` to convert the .mp3 and then runs the python script - tagmotifs.py
in order to extract the answers from the gm.log file and insert them as id3 tags in the .mp3 files.
The .mp3 files are written to a directory tree under 'gm_mp3'.
